{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XhdimaIlRVNxAKsvfrQJtY_SEvjvVLvi",
      "authorship_tag": "ABX9TyNkrJGhPiW4gTWtLrGvsm1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iejjlopez/HolaJJ/blob/master/ProyectoRecomendador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 1: Preparación del Entorno\n",
        "Abra Google Colab.\n",
        "Cree un nuevo notebook de Python.\n",
        "Paso 2: Importar Bibliotecas"
      ],
      "metadata": {
        "id": "RfawjTRXcfSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5iNRaW9s-Hr",
        "outputId": "ce9ec59b-1796-4d0e-83a4-6a1f350a2a93"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7CcSimicqMR",
        "outputId": "f0eb6577-7a2e-4eab-d38d-449e0d46ceb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/772.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/772.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m532.5/772.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3162997 sha256=96610d4df4715ada0c7da3135c3328f9d76943e7e027b3f0e5be299df9374dec\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7PJCNyMDcHI5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import cosine\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from surprise import Dataset, Reader, KNNBasic, KNNWithMeans, SVD, SVDpp, NMF, CoClustering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Glr_q22WceIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Cargar el archivo de datos\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/ICARO/Proyecto Recomendacion/ratings_Electronics_2.csv'\n",
        "data = pd.read_csv(file_path, names=['userId', 'productId', 'rating', 'timestamp'])\n",
        "\n",
        "# Mostrar el nombre del archivo en la impresión\n",
        "print(f\"Nombres de las columnas en el DataFrame del archivo '{file_path}':\")\n",
        "column_names = data.columns\n",
        "print(column_names)\n",
        "\n",
        "# Visualizar los primeros 5 registros del DataFrame\n",
        "print(f\"\\nPrimeros 5 registros del DataFrame del archivo '{file_path}':\")\n",
        "print(data.head())\n",
        "\n",
        "# Estadísticas descriptivas\n",
        "print(f\"\\nEstadísticas descriptivas del DataFrame del archivo '{file_path}':\")\n",
        "print(data.describe())\n",
        "\n",
        "# Sobrescribir el archivo CSV original con los nuevos nombres de columnas\n",
        "data.to_csv(file_path, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKW7bNuGRQhq",
        "outputId": "b80412b8-8408-493c-909b-5086c1d79e1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-dae848d45cf3>:8: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(file_path, names=['userId', 'productId', 'rating', 'timestamp'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombres de las columnas en el DataFrame del archivo '/content/drive/MyDrive/Colab Notebooks/ICARO/Proyecto Recomendacion/ratings_Electronics_2.csv':\n",
            "Index(['userId', 'productId', 'rating', 'timestamp'], dtype='object')\n",
            "\n",
            "Primeros 5 registros del DataFrame del archivo '/content/drive/MyDrive/Colab Notebooks/ICARO/Proyecto Recomendacion/ratings_Electronics_2.csv':\n",
            "           userId   productId  rating   timestamp\n",
            "0            user        prod  rating   timestamp\n",
            "1   AKM1MP6P0OYPR  0132793040     5.0  1365811200\n",
            "2  A2CX7LUOHB2NDG  0321732944     5.0  1341100800\n",
            "3  A2NWSAGRHCP8N5  0439886341     1.0  1367193600\n",
            "4  A2WNBOD3WNDNKT  0439886341     3.0  1374451200\n",
            "\n",
            "Estadísticas descriptivas del DataFrame del archivo '/content/drive/MyDrive/Colab Notebooks/ICARO/Proyecto Recomendacion/ratings_Electronics_2.csv':\n",
            "               userId   productId     rating   timestamp\n",
            "count         7824483     7824483  7824483.0     7824483\n",
            "unique        4201697      476003       11.0       10013\n",
            "top     A5JLAU2ARJ0BO  B0074BW614        5.0  1389052800\n",
            "freq              520       18244  4275281.0       18139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "05dB80uUVZGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sm2Ev3nVY5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el archivo de datos\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ICARO/Proyecto Recomendacion/ratings_Electronics_2.csv')\n",
        "\n",
        "# Verificar los nombres de las columnas\n",
        "column_names = data.columns\n",
        "print(\"Nombres de las columnas en el DataFrame:\")\n",
        "print(column_names)\n",
        "\n",
        "# Comprobar si 'timestamp' está presente en los nombres de las columnas\n",
        "if 'timestamp' in column_names:\n",
        "    print(\"'timestamp' está presente en el DataFrame.\")\n",
        "else:\n",
        "    print(\"La columna 'timestamp' no está presente en el DataFrame. Verifica los nombres de las columnas.\")\n",
        "\n",
        "# Acceder a los primeros registros para visualizar los datos\n",
        "print(\"\\nPrimeros registros del DataFrame:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSFR8NFVmRmU",
        "outputId": "643672e7-bce6-40e4-96fa-e7f0b4edaa74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-50b511491a25>:4: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ICARO/Proyecto Recomendacion/ratings_Electronics_2.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombres de las columnas en el DataFrame:\n",
            "Index(['userId', 'productId', 'rating', 'timestamp'], dtype='object')\n",
            "'timestamp' está presente en el DataFrame.\n",
            "\n",
            "Primeros registros del DataFrame:\n",
            "           userId   productId  rating   timestamp\n",
            "0            user        prod  rating   timestamp\n",
            "1   AKM1MP6P0OYPR  0132793040     5.0  1365811200\n",
            "2  A2CX7LUOHB2NDG  0321732944     5.0  1341100800\n",
            "3  A2NWSAGRHCP8N5  0439886341     1.0  1367193600\n",
            "4  A2WNBOD3WNDNKT  0439886341     3.0  1374451200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código proporcionado implementa un sistema de recomendación de productos utilizando diferentes algoritmos de filtrado colaborativo y análisis de contenido. Los pasos principales y objetivos del código son:\n",
        "\n",
        "Carga de datos: Se carga el archivo CSV con las calificaciones de los usuarios sobre los productos.\n",
        "\n",
        "Exploración de datos: Se imprimen los primeros registros del DataFrame, el número de registros y el número de valores faltantes en cada columna.\n",
        "\n",
        "Preprocesamiento de datos: Se renombran las columnas del DataFrame y se agrupan los datos por usuario y producto.\n",
        "\n",
        "Filtrado colaborativo: Se implementan diferentes algoritmos de filtrado colaborativo, como KNNBasic, KNNWithMeans, SVD, SVDpp, NMF y CoClustering. Se entrena cada algoritmo con los datos de entrenamiento y se evalúa su rendimiento mediante la puntuación MAP (Mean Average Precision).\n",
        "\n",
        "Análisis de contenido: Se realiza un análisis de contenido utilizando la biblioteca scikit-learn. Se calcula la matriz de distancias entre los productos utilizando la distancia coseno y se generan recomendaciones de productos para cada usuario. Se evalúa el rendimiento del análisis de contenido mediante la puntuación MAP.\n",
        "\n",
        "Comparación de resultados: Se comparan los resultados de los diferentes algoritmos de filtrado colaborativo y el análisis de contenido mediante un gráfico de barras que muestra la puntuación MAP para cada algoritmo.\n",
        "\n",
        "El objetivo principal del código es evaluar y comparar el rendimiento de diferentes algoritmos de recomendación de productos utilizando datos de calificaciones de usuarios y productos."
      ],
      "metadata": {
        "id": "CBVx5DuySTCw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paso 3: Cargar y Preprocesar los Datos"
      ],
      "metadata": {
        "id": "mOR3-tbEc-_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from surprise import Dataset, Reader, KNNBasic, KNNWithMeans, SVD, SVDpp, NMF, CoClustering\n",
        "from surprise.model_selection import train_test_split\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/ICARO/Proyecto Recomendacion/ratings_Electronics_2.csv'\n",
        "data = pd.read_csv(file_path, names=['userId', 'productId', 'rating', 'timestamp'], dtype=str)\n",
        "\n",
        "# Seleccionar un subconjunto aleatorio de usuarios\n",
        "random_users = np.random.choice(data['userId'].unique(), size=100, replace=False)\n",
        "subset_data = data[data['userId'].isin(random_users)]\n",
        "\n",
        "# Convertir la columna de timestamp a formato de fecha y hora\n",
        "subset_data['timestamp'] = pd.to_datetime(subset_data['timestamp'], unit='s')\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "train_start = '2022-01-01'\n",
        "train_end = '2022-06-30'\n",
        "test_start = '2022-07-01'\n",
        "test_end = '2022-12-31'\n",
        "train_data = subset_data[(subset_data['timestamp'] >= train_start) & (subset_data['timestamp'] <= train_end)]\n",
        "test_data = subset_data[(subset_data['timestamp'] >= test_start) & (subset_data['timestamp'] <= test_end)]\n",
        "\n",
        "# Crear un objeto Surprise Dataset a partir de los datos de entrenamiento\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "train_dataset = Dataset.load_from_df(train_data[['userId', 'productId', 'rating']], reader)\n",
        "\n",
        "# Entrenar y evaluar los algoritmos de filtrado colaborativo\n",
        "algorithms = [KNNBasic(), KNNWithMeans(), SVD(), SVDpp(), NMF(), CoClustering()]\n",
        "map_scores = {}\n",
        "\n",
        "for algorithm in algorithms:\n",
        "    algorithm.fit(train_dataset.build_full_trainset())\n",
        "    predictions = algorithm.test(test_data[['userId', 'productId', 'rating']].values)\n",
        "\n",
        "    if predictions:\n",
        "        y_true = [pred.r_ui for pred in predictions]\n",
        "        y_scores = [pred.est for pred in predictions]\n",
        "        map_score = average_precision_score(y_true, y_scores)\n",
        "    else:\n",
        "        map_score = 0.0\n",
        "\n",
        "    map_scores[algorithm.__class__.__name__] = map_score\n",
        "\n",
        "# Imprimir los resultados del MAP para cada algoritmo\n",
        "for algorithm_name, map_score in map_scores.items():\n",
        "    print(f\"{algorithm_name}: {map_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QFGVdONgLxP",
        "outputId": "c2350a13-b3cc-4a6c-c9e5-33c6c469acbd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "KNNBasic: 0.0\n",
            "KNNWithMeans: 0.0\n",
            "SVD: 0.0\n",
            "SVDpp: 0.0\n",
            "NMF: 0.0\n",
            "CoClustering: 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-8ec6acfe84f8>:16: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
            "  subset_data['timestamp'] = pd.to_datetime(subset_data['timestamp'], unit='s')\n",
            "<ipython-input-6-8ec6acfe84f8>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  subset_data['timestamp'] = pd.to_datetime(subset_data['timestamp'], unit='s')\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ItZOIA5xgLps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "falta memoria"
      ],
      "metadata": {
        "id": "gEINF5PCZYVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cargar el archivo CSV\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/ICARO/Proyecto Recomendacion/ratings_Electronics_2.csv'\n",
        "data = pd.read_csv(file_path, names=['userId', 'productId', 'rating', 'timestamp'], dtype={'userId': str, 'productId': str, 'rating': str, 'timestamp': str})\n",
        "data = data.dropna(subset=['rating'])  # Eliminar filas con valores nulos en la columna 'rating'\n",
        "data['rating'] = pd.to_numeric(data['rating'], errors='coerce')  # Convertir la columna 'rating' a numérica\n",
        "data = data.dropna(subset=['rating'])  # Eliminar filas con valores no numéricos en la columna 'rating'\n",
        "\n",
        "\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "data = data.rename(columns={'userId': 'account_id', 'productId': 'content_id', 'rating': 'counts'})\n",
        "data_grouped = data.groupby(['account_id', 'content_id']).size().reset_index(name='counts')\n",
        "\n",
        "# Filtrado colaborativo\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "train_data = Dataset.load_from_df(data_grouped[['account_id', 'content_id', 'counts']], reader)\n",
        "train_data = train_data.build_full_trainset()\n",
        "\n",
        "# SVDpp\n",
        "algo_svdpp = SVDpp(n_epochs=5, reg_all=0.4, random_state=42)\n",
        "algo_svdpp.fit(train_data)\n",
        "predictions_svdpp = algo_svdpp.test(train_data.build_testset())\n",
        "map_svdpp = average_precision_score(list(zip(*predictions_svdpp))[0], list(zip(*predictions_svdpp))[3])\n",
        "\n",
        "# SVD\n",
        "algo_svd = SVD()\n",
        "algo_svd.fit(train_data)\n",
        "predictions_svd = algo_svd.test(train_data.build_testset())\n",
        "map_svd = average_precision_score(list(zip(*predictions_svd))[0], list(zip(*predictions_svd))[3])\n",
        "\n",
        "# NMF\n",
        "algo_nmf = NMF()\n",
        "algo_nmf.fit(train_data)\n",
        "predictions_nmf = algo_nmf.test(train_data.build_testset())\n",
        "map_nmf = average_precision_score(list(zip(*predictions_nmf))[0], list(zip(*predictions_nmf))[3])\n",
        "\n",
        "# CoClustering\n",
        "algo_coclustering = CoClustering()\n",
        "algo_coclustering.fit(train_data)\n",
        "predictions_coclustering = algo_coclustering.test(train_data.build_testset())\n",
        "map_coclustering = average_precision_score(list(zip(*predictions_coclustering))[0], list(zip(*predictions_coclustering))[3])\n",
        "\n",
        "# Análisis de contenido\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "content_tfidf = tfidf.fit_transform(data_grouped['content_id'])\n",
        "distances = pairwise_distances(content_tfidf, metric='cosine')\n",
        "n_neighbors = 10\n",
        "nbrs = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine').fit(content_tfidf)\n",
        "distances, indices = nbrs.kneighbors(content_tfidf)\n",
        "content_recommendations = []\n",
        "for i in range(len(indices)):\n",
        "    content_recommendations.append(data_grouped['content_id'][indices[i][1:]])\n",
        "map_contenido = average_precision_score([data_grouped['content_id'][i] for i in data_grouped['account_id']], content_recommendations)\n",
        "\n",
        "# Comparación de resultados\n",
        "map_scores = [map_svdpp, map_svd, map_nmf, map_coclustering, map_contenido]\n",
        "algorithms = ['SVDpp', 'SVD', 'NMF', 'CoClustering', 'Análisis de Contenido']\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(algorithms, map_scores, color='skyblue')\n",
        "plt.xlabel('Algoritmo')\n",
        "plt.ylabel('MAP')\n",
        "plt.title('Comparación de MAP entre algoritmos')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4hVSV-hmUQZ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}